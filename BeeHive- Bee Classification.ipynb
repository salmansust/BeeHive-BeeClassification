{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nimport os as os\nimport random\nfrom pathlib import Path\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\nimport tensorflow","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IMAGE_PATH = '../input/honey-bee-annotated-images/bee_imgs/bee_imgs/'\nIMAGE_WIDTH = 100\nIMAGE_HEIGHT = 100\nIMAGE_CHANNELS = 3\nRANDOM_STATE = 2018\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2\nCONV_2D_DIM_1 = 16\nCONV_2D_DIM_2 = 16\nCONV_2D_DIM_3 = 32\nCONV_2D_DIM_4 = 64\nMAX_POOL_DIM = 2\nKERNEL_SIZE = 3\nBATCH_SIZE = 32\nNO_EPOCHS_1 = 5\nNO_EPOCHS_2 = 15\nNO_EPOCHS_3 = 50\nPATIENCE = 5\nVERBOSE = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input/honey-bee-annotated-images/\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nbee_data = pd.read_csv(\"../input/honey-bee-annotated-images/bee_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bee_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bee_data.sample(100).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data contains the following values:\n\n* file - the image file name;\n* date - the date when the picture was taken;\n* time - the time when the picture was taken;\n* location - the US location, with city, state and country names;\n* zip code - the ZIP code associated with the location;\n* subspecies - the subspecies to whom the bee in the current image belongs;\n* health - this is the health state of the bee in the current image;\n* pollen_carrying - indicates if the picture shows the bee with pollen attached to the legs;\n* caste - the bee caste;\n\nIt is important, before going to create a model, to have a good understanding of the data. We will therefore explore the various features, not only the images."},{"metadata":{},"cell_type":"markdown","source":"Let's create a function that check for missing data in the dataset.****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data(bee_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_names = list(bee_data['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image_sizes(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    return list(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = np.stack(bee_data['file'].apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h','c'])\nbee_data = pd.concat([bee_data,df],axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traceW = go.Box(\n    x = bee_data['w'],\n    name=\"Width\",\n     marker=dict(\n                color='rgba(238,23,11,0.5)',\n                line=dict(\n                    color='red',\n                    width=1.2),\n            ),\n    orientation='h')\ntraceH = go.Box(\n    x = bee_data['h'],\n    name=\"Height\",\n    marker=dict(\n                color='rgba(11,23,245,0.5)',\n                line=dict(\n                    color='blue',\n                    width=1.2),\n            ),\n    orientation='h')\ndata = [traceW, traceH]\nlayout = dict(title = 'Width & Heights of images',\n          xaxis = dict(title = 'Size', showticklabels=True), \n          yaxis = dict(title = 'Image dimmension'),\n          hovermode = 'closest',\n         )\nfig = dict(data=data, layout=layout)\niplot(fig, filename='width-height')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the locations of the images. For this, we will group by location and zip code.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['zip code'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bee_data = bee_data.replace({'location':'Athens, Georgia, USA'}, 'Athens, GA, USA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['zip code'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf['code'] = df['location'].map(lambda x: x.split(',', 2)[1])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Bar(\n        x = df['location'],\n        y = df['Images'],\n        marker=dict(color=\"Tomato\"),\n        text=df['location']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per location',\n          xaxis = dict(title = 'Subspecies', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-location')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list of locations\nlocations = (bee_data.groupby(['location'])['location'].nunique()).index\n\ndef draw_category_images(var,cols=5):\n    categories = (bee_data.groupby([var])[var].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=cols, figsize=(2*cols,2*len(categories)))\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = bee_data[bee_data[var]==cat].sample(cols)\n        for j in range(0,cols):\n            file=IMAGE_PATH + sample.iloc[j]['file']\n            im=imageio.imread(file)\n            ax[i, j].imshow(im, resample=True)\n            ax[i, j].set_title(cat, fontsize=9)  \n    plt.tight_layout()\n    plt.show()\n    \ndraw_category_images(\"location\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's first convert date to datetime and extract year, month and day. We also convert time and extract hour and minute.Then plot the date/time distribution of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"bee_data['date_time'] = pd.to_datetime(bee_data['date'] + ' ' + bee_data['time'])\nbee_data[\"year\"] = bee_data['date_time'].dt.year\nbee_data[\"month\"] = bee_data['date_time'].dt.month\nbee_data[\"day\"] = bee_data['date_time'].dt.day\nbee_data[\"hour\"] = bee_data['date_time'].dt.hour\nbee_data[\"minute\"] = bee_data['date_time'].dt.minute\n\ntmp = bee_data.groupby(['date_time', 'hour'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\nhover_text = []\nfor index, row in df.iterrows():\n    hover_text.append(('Date/time: {}<br>'+\n                      'Hour: {}<br>'+\n                      'Location: {}<br>'+\n                      'Images: {}').format(row['date_time'],\n                                            row['hour'],\n                                            row['location'],\n                                            row['Images']))\ndf['hover_text'] = hover_text\nlocations = (bee_data.groupby(['location'])['location'].nunique()).index\ndata = []\nfor location in locations:\n    dfL = df[df['location']==location]\n    trace = go.Scatter(\n        x = dfL['date_time'],y = dfL['hour'],\n        name=location,\n        marker=dict(\n            symbol='circle',\n            sizemode='area',\n            sizeref=0.2,\n            size=dfL['Images'],\n            line=dict(\n                width=2\n            ),),\n        mode = \"markers\",\n        text=dfL['hover_text'],\n    )\n    data.append(trace)\n    \nlayout = dict(title = 'Number of bees images per date, approx. hour and location',\n          xaxis = dict(title = 'Date', showticklabels=True), \n          yaxis = dict(title = 'Hour'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\n\niplot(fig, filename='images-date_time')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_category_images(\"hour\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot now the subspecies distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['subspecies'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Bar(\n        x = df['subspecies'],\n        y = df['Images'],\n        marker=dict(color=\"Green\"),\n        text=df['subspecies']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per subspecies',\n          xaxis = dict(title = 'Subspecies', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-subspecies')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_category_images(\"subspecies\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subspeiecs with location and image."},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['subspecies'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\n\npiv = pd.pivot_table(df, values=\"Images\",index=[\"subspecies\"], columns=[\"location\"], fill_value=0)\nm = piv.values\n\ntrace = go.Heatmap(z = m, y= list(piv.index), x=list(piv.columns),colorscale='Rainbow',reversescale=False)\n    \ndata=[trace]\nlayout = dict(title = \"Number of images per subspecies and location\",\n              xaxis = dict(title = 'Location',\n                        showticklabels=True,\n                           tickangle = 45,\n                        tickfont=dict(\n                                size=10,\n                                color='black'),\n                          ),\n              yaxis = dict(title = 'Subspecies', \n                        showticklabels=True, \n                           tickangle = 45,\n                        tickfont=dict(\n                            size=10,\n                            color='black'),\n                      ), \n              hovermode = 'closest',\n              showlegend=False,\n                  width=600,\n                  height=600,\n             )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-location_subspecies')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subspecies and hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['subspecies'])['hour'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\npiv = pd.pivot_table(df, values=\"Images\",index=[\"subspecies\"], columns=[\"hour\"], fill_value=0)\nm = piv.values\ntrace = go.Heatmap(z = m, y= list(piv.index), x=list(piv.columns),colorscale='Rainbow',reversescale=False)\n    \ndata=[trace]\nlayout = dict(title = \"Number of images per subspecies and hour\",\n              xaxis = dict(title = 'Hour',\n                        showticklabels=True,\n                           tickangle = 0,\n                        tickfont=dict(\n                                size=10,\n                                color='black'),\n                          ),\n              yaxis = dict(title = 'Subspecies', \n                        showticklabels=True, \n                           tickangle = 45,\n                        tickfont=dict(\n                            size=10,\n                            color='black'),\n                      ), \n              hovermode = 'closest',\n              showlegend=False,\n                  width=600,\n                  height=600,\n             )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-location_subspecies')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's draw the image size distribution (width and height) grouped by subspecies"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_trace_box(dataset,var, subspecies):\n    dfS = dataset[dataset['subspecies']==subspecies];\n    trace = go.Box(\n        x = dfS[var],\n        name=subspecies,\n        marker=dict(\n                    line=dict(\n                        color='black',\n                        width=0.8),\n                ),\n        text=dfS['subspecies'], \n        orientation = 'h'\n    )\n    return trace\n\nsubspecies = (bee_data.groupby(['subspecies'])['subspecies'].nunique()).index\ndef draw_group(dataset, var, title,height=500):\n    data = list()\n    for subs in subspecies:\n        data.append(draw_trace_box(dataset, var, subs))\n        \n    layout = dict(title = title,\n              xaxis = dict(title = 'Size',showticklabels=True),\n              yaxis = dict(title = 'Subspecies', showticklabels=True, tickfont=dict(\n                family='Old Standard TT, serif',\n                size=8,\n                color='black'),), \n              hovermode = 'closest',\n              showlegend=False,\n                  width=600,\n                  height=height,\n             )\n    fig = dict(data=data, layout=layout)\n    iplot(fig, filename='subspecies-image')\n\n\ndraw_group(bee_data, 'w', \"Width of images per subspecies\")\ndraw_group(bee_data, 'h', \"Height of images per subspecies\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_trace_scatter(dataset, subspecies):\n    dfS = dataset[dataset['subspecies']==subspecies];\n    trace = go.Scatter(\n        x = dfS['w'],y = dfS['h'],\n        name=subspecies,\n        mode = \"markers\",\n        marker = dict(opacity=0.8),\n        text=dfS['subspecies'], \n    )\n    return trace\n\nsubspecies = (bee_data.groupby(['subspecies'])['subspecies'].nunique()).index\ndef draw_group(dataset, title,height=600):\n    data = list()\n    for subs in subspecies:\n        data.append(draw_trace_scatter(dataset, subs))\n        \n    layout = dict(title = title,\n              xaxis = dict(title = 'Width',showticklabels=True),\n              yaxis = dict(title = 'Height', showticklabels=True, tickfont=dict(\n                family='Old Standard TT, serif',\n                size=8,\n                color='black'),), \n              hovermode = 'closest',\n              showlegend=True,\n                  width=800,\n                  height=height,\n             )\n    fig = dict(data=data, layout=layout)\n    iplot(fig, filename='subspecies-image')\n\ndraw_group(bee_data,  \"Width and height of images per subspecies\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's plot now the health distribution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['health'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Bar(\n        x = df['health'],\n        y = df['Images'],\n        marker=dict(color=\"Red\"),\n        text=df['health']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per health',\n          xaxis = dict(title = 'Health', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-health')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['subspecies'])['health'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"piv = pd.pivot_table(df, values=\"Images\",index=[\"subspecies\"], columns=[\"health\"], fill_value=0)\nm = piv.values\ntrace = go.Heatmap(z = m, y= list(piv.index), x=list(piv.columns),colorscale='Rainbow',reversescale=False)\n    \ndata=[trace]\nlayout = dict(title = \"Number of images per subspecies and health\",\n              xaxis = dict(title = 'Subspecies',\n                        showticklabels=True,\n                           tickangle = 45,\n                        tickfont=dict(\n                                size=10,\n                                color='black'),\n                          ),\n              yaxis = dict(title = 'Health', \n                        showticklabels=True, \n                           tickangle = 45,\n                        tickfont=dict(\n                            size=10,\n                            color='black'),\n                      ), \n              hovermode = 'closest',\n              showlegend=False,\n                  width=600,\n                  height=600,\n             )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-health_subspecies')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['health', 'location'])['subspecies'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\nhover_text = []\nfor index, row in df.iterrows():\n    hover_text.append(('Subspecies: {}<br>'+\n                      'Health: {}<br>'+\n                      'Location: {}<br>'+\n                      'Images: {}').format(row['subspecies'],\n                                            row['health'],\n                                            row['location'],\n                                            row['Images']))\ndf['hover_text'] = hover_text\nsubspecies = (bee_data.groupby(['subspecies'])['subspecies'].nunique()).index\ndata = []\nfor subs in subspecies:\n    dfL = df[df['subspecies']==subs]\n    trace = go.Scatter(\n        x = dfL['location'],y = dfL['health'],\n        name=subs,\n        marker=dict(\n            symbol='circle',\n            sizemode='area',\n            sizeref=0.2,\n            size=dfL['Images'],\n            line=dict(\n                width=2\n            ),),\n        mode = \"markers\",\n        text=dfL['hover_text'],\n    )\n    data.append(trace)\n    \nlayout = dict(title = 'Number of bees images per location, health and subspecies',\n          xaxis = dict(title = 'Location', showticklabels=True), \n          yaxis = dict(title = 'Health', tickangle=45),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-subspecies-health-location')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot image for each health catagory\ndraw_category_images(\"health\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pollen Carrying distrubution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['pollen_carrying'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only 18 out of 5172 (0.34%) of the images are of bees carrying pollen"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = bee_data.groupby(['pollen_carrying'])['subspecies'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf[df['pollen_carrying']==True]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Majority of pollen carrying bees are of unknown species (67%) and the rest (33%) are Italian honey bee."},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_category_images(\"pollen_carrying\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split the whole dataset in train and test. We will use random_state to ensure reproductibility of results.\n\nThe train-test split is 80% for training set and 20% for test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(bee_data, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n\ntrain_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE)\n\nprint(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next step in our creation of a predictive model is to create a simple model, a baseline model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#A function for reading images from the image files, scale all images to 100 x 100 x 3 (channels).\n\ndef read_image(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), mode='reflect')\n    return image[:,:,:IMAGE_CHANNELS]\n\n\n#A function to create the dummy variables corresponding to the categorical target variable.\n\ndef categories_encoder(dataset, var='subspecies'):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = pd.get_dummies(dataset[var], drop_first=False)\n    return X, y\n\nX_train, y_train = categories_encoder(train_df)\nX_val, y_val = categories_encoder(val_df)\nX_test, y_test = categories_encoder(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building CNN Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=Sequential()\nmodel1.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel1.add(MaxPool2D(MAX_POOL_DIM))\nmodel1.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\nmodel1.add(Flatten())\nmodel1.add(Dense(y_train.columns.size, activation='softmax'))\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are also using a **ImageDataGenerator** that creates random variation of the training dataset, by applying various techniques, including:\n\n* rotation (in a range of 0-180 degrees) of the original images;\n* zoom (10%);\n* shift in horizontal and in vertical direction (10%);\n* horizontal and vertical flip;"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_generator = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=180,\n        zoom_range = 0.1, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True,\n        vertical_flip=True)\nimage_generator.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We train the first model using **fit_generator** and a predefined batch size. The **steps_per_epoch** is calculated to be size of the training set divided by the batch size. We are using the predefined epoch number for this first experiment (5 steps) and as well validation, using the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model1  = model1.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                        epochs=NO_EPOCHS_1,\n                        validation_data=[X_val, y_val],\n                        steps_per_epoch=len(X_train)/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model1.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])\ntest_accuracy_report(model1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We add two Dropout layers. The role of the Dropout layers is to reduce the overfitting, by dropping, each training epoch, a certain percent of the nodes connections (by rotation). This is equivalent of using less training data and in the same time training the network with various data as well as using parallel alternative networks, thus reducing the likelihood that the network will overfit the train data.\n\nThe definition of the second model is:"},{"metadata":{},"cell_type":"markdown","source":"**CNN Model2 with Dropout**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2=Sequential()\nmodel2.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel2.add(MaxPool2D(MAX_POOL_DIM))\nmodel2.add(Dropout(0.4))\nmodel2.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\nmodel2.add(Dropout(0.4))\nmodel2.add(Flatten())\nmodel2.add(Dense(y_train.columns.size, activation='softmax'))\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model2  = model2.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                        epochs=NO_EPOCHS_2,\n                        validation_data=[X_val, y_val],\n                        steps_per_epoch=len(X_train)/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_accuracy_report(model2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}